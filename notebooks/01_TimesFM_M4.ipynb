{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dNLON8aPcbt"
      },
      "outputs": [],
      "source": [
        "# --- SETUP & IMPORTS ---\n",
        "import timesfm  # Ensure you run: pip install git+https://github.com/google-research/timesfm.git\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Verify GPU\n",
        "device = \"gpu\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"‚úÖ Using device: {device.upper()}\")\n",
        "\n",
        "# --- CELL 2: LOAD TIMESFM 2.0 MODEL ---\n",
        "# Official 2.0 Checkpoint (500M Parameters)\n",
        "CHECKPOINT_REPO = \"google/timesfm-2.0-500m-pytorch\"\n",
        "\n",
        "# Configuration for TimesFM 2.0\n",
        "# Note: 2.0 supports up to 2048 context length (vs 512 in 1.0)\n",
        "CONTEXT_LEN = 2048\n",
        "HORIZON_LEN = 14       # Forecast horizon\n",
        "\n",
        "print(f\"Loading TimesFM 2.0 from {CHECKPOINT_REPO}...\")\n",
        "\n",
        "tfm = timesfm.TimesFm(\n",
        "    context_len=CONTEXT_LEN,\n",
        "    horizon_len=HORIZON_LEN,\n",
        "    input_patch_len=32,\n",
        "    output_patch_len=128,\n",
        "    num_layers=50,\n",
        "    model_dims=1280,\n",
        "    quantiles=[0.1, 0.5, 0.9],\n",
        "    backend=device\n",
        ")\n",
        "\n",
        "# Load the 2.0 Weights\n",
        "tfm.load_from_checkpoint(repo_id=CHECKPOINT_REPO)\n",
        "print(\"‚úÖ TimesFM 2.0 Model loaded successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- DATA PREP ---\n",
        "DATA_PATH = \"../data/m4_processed.csv\"  # Output from your data_prep.ipynb\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(DATA_PATH)\n",
        "    print(f\"‚úÖ Loaded Data: {df.shape}\")\n",
        "\n",
        "    # Example Inference Call\n",
        "    # Note: Ensure your DF has 'unique_id', 'ds', 'y' columns standard for TimesFM\n",
        "    forecast_df = tfm.forecast_on_df(\n",
        "        inputs=df,\n",
        "        freq=\"D\",  # D = Daily\n",
        "        value_name=\"sales\",\n",
        "        num_jobs=-1\n",
        "    )\n",
        "    print(\"‚úÖ Inference Complete\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"‚ùå Error: Could not find {DATA_PATH}. Run 00_Data_Processing.ipynb first.\")"
      ],
      "metadata": {
        "id": "Yi5GvaW6RTw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- EVALUATION & RESULTS ---\n",
        "\n",
        "def calculate_metrics(y_true, y_pred, y_train_mean=1.0):\n",
        "    \"\"\"\n",
        "    Standard Forecasting Metrics\n",
        "    \"\"\"\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "\n",
        "    # Avoid division by zero\n",
        "    epsilon = 1e-10\n",
        "\n",
        "    # MAE & MSE\n",
        "    mae = np.mean(np.abs(y_true - y_pred))\n",
        "    mse = np.mean((y_true - y_pred) ** 2)\n",
        "    rmse = np.sqrt(mse)\n",
        "\n",
        "    # sMAPE (Symmetric Mean Absolute Percentage Error)\n",
        "    smape = 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred) + epsilon))\n",
        "\n",
        "    # MASE (Mean Absolute Scaled Error)\n",
        "    # Note: Strictly speaking, MASE requires the Naive error from the training set.\n",
        "    # For Zero-Shot benchmarks, we often approximate the scale using the mean value\n",
        "    # or the simple MAE if training data isn't available in memory.\n",
        "    # Here we use the mean of the actuals to normalize, which is a common proxy for magnitude.\n",
        "    mase = mae / (np.mean(np.abs(y_true)) + epsilon)\n",
        "\n",
        "    return {\"MAE\": mae, \"MSE\": mse, \"RMSE\": rmse, \"sMAPE\": smape, \"MASE\": mase}\n",
        "\n",
        "print(\"\\n--- Processing Results ---\")\n",
        "\n",
        "# 1. Standardize Columns for Merge\n",
        "# Ensure both have 'unique_id' and 'ds' (date) columns\n",
        "if 'series_id' in df.columns:\n",
        "    df = df.rename(columns={'series_id': 'unique_id'})\n",
        "if 'date' in df.columns:\n",
        "    df = df.rename(columns={'date': 'ds'})\n",
        "\n",
        "# 2. Merge Forecast with Ground Truth\n",
        "# TimesFM output usually has columns: ['unique_id', 'ds', 'timesfm']\n",
        "results_df = df.merge(forecast_df, on=['unique_id', 'ds'], how='inner')\n",
        "\n",
        "# 3. Calculate Metrics\n",
        "# Assuming your ground truth column is named 'sales' or 'value'.\n",
        "# We try both just in case.\n",
        "target_col = 'sales' if 'sales' in results_df.columns else 'value'\n",
        "pred_col = 'timesfm' # Default output column from TimesFM\n",
        "\n",
        "if target_col in results_df.columns and pred_col in results_df.columns:\n",
        "    metrics = calculate_metrics(results_df[target_col], results_df[pred_col])\n",
        "\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(f\"üèÜ FINAL RESULTS ({target_col.upper()})\")\n",
        "    print(\"=\"*40)\n",
        "    print(f\"MAE:   {metrics['MAE']:.4f}\")\n",
        "    print(f\"MSE:   {metrics['MSE']:.4f}\")\n",
        "    print(f\"RMSE:  {metrics['RMSE']:.4f}\")\n",
        "    print(f\"sMAPE: {metrics['sMAPE']:.4f}%\")\n",
        "    print(f\"MASE:  {metrics['MASE']:.4f} (Approx)\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    # Optional: Plot the first series to visually verify\n",
        "    print(\"\\nVisualizing first series...\")\n",
        "    first_id = results_df['unique_id'].unique()[0]\n",
        "    sample = results_df[results_df['unique_id'] == first_id].tail(100)\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(sample['ds'], sample[target_col], label='Actual', color='black')\n",
        "    plt.plot(sample['ds'], sample[pred_col], label='TimesFM Forecast', color='blue', linestyle='--')\n",
        "    plt.title(f\"Forecast vs Actual: {first_id}\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    print(f\"‚ùå Error: Could not find target column '{target_col}' or prediction column '{pred_col}' in merged data.\")\n",
        "    print(\"Columns found:\", results_df.columns)"
      ],
      "metadata": {
        "id": "tqD-jVzYSLo_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}